from celery import Celery
import os
import httpx
import traceback

REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

app = Celery(
    'credisource',
    broker=REDIS_URL,
    backend=REDIS_URL
)

app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
)

# API Keys from environment
AIORNOT_API_KEY = os.getenv("AIORNOT_API_KEY")
SAPLING_API_KEY = os.getenv("SAPLING_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_SEARCH_API_KEY")
GOOGLE_SEARCH_ENGINE_ID = os.getenv("GOOGLE_SEARCH_ENGINE_ID")
HUGGINGFACE_API_KEY = os.getenv("HUGGINGFACE_API_KEY")
WINSTON_API_KEY = os.getenv("WINSTON_API_KEY")

@app.task(name='credisource.test_task')
def test_task():
    return {"status": "Worker is running!"}

@app.task(name='credisource.verify_content')
def verify_content_task(job_id, url, content_type):
    """Process verification job with REAL AI detection"""
    
    print(f"üîç Processing job {job_id} for {url} (type: {content_type})")
    
    try:
        # Run detection based on content type
        if content_type in ['image', 'video']:
            result = detect_image_video(url)
        elif content_type == 'text':
            result = detect_text(url)
        else:
            result = {"error": "Unsupported content type"}
        
        print(f"‚úÖ Completed job {job_id}: Score {result.get('trust_score', {}).get('score', 'N/A')}")
        return result
        
    except Exception as e:
        print(f"‚ùå Error in job {job_id}: {str(e)}")
        return {
            "job_id": job_id,
            "status": "failed",
            "error": str(e)
        }

@app.task(name='credisource.verify_content_file')
def verify_content_file_task(job_id, file_base64, filename, content_type):
    """Process verification job for uploaded files"""
    
    print(f"üîç Processing uploaded file job {job_id}: {filename} (type: {content_type})")
    
    try:
        import base64
        
        # Decode file from base64
        file_data = base64.b64decode(file_base64)
        print(f"üì¶ Decoded file: {len(file_data)} bytes")
        
        # Run detection based on content type
        if content_type == 'image':
            result = detect_image_video_from_data(file_data, filename)
        elif content_type == 'video':
            # Videos use the same detection as images (AIorNOT supports both)
            print(f"üé¨ Processing video file...")
            result = detect_image_video_from_data(file_data, filename, is_video=True)
        elif content_type == 'text':
            # For text files, decode as string
            text_content = file_data.decode('utf-8')
            result = detect_text(text_content)
        else:
            result = {"error": "Unsupported content type"}
        
        print(f"‚úÖ Completed file job {job_id}: Score {result.get('trust_score', {}).get('score', 'N/A')}")
        return result
        
    except Exception as e:
        print(f"‚ùå Error in file job {job_id}: {str(e)}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")
        return {
            "job_id": job_id,
            "status": "failed",
            "error": str(e)
        }

def reverse_image_search(url):
    """Use Google to find where this image appears online"""
    
    if not GOOGLE_API_KEY or not GOOGLE_SEARCH_ENGINE_ID:
        print("‚ö†Ô∏è Google Search not configured, skipping")
        return None
    
    try:
        print(f"üîç Running Google Search for image context...")
        
        # Extract filename and domain from URL for better search
        from urllib.parse import urlparse
        parsed = urlparse(url)
        filename = parsed.path.split('/')[-1]
        domain = parsed.netloc
        
        # Search for the image URL and filename
        search_query = f'"{url}" OR "{filename}"'
        
        with httpx.Client(timeout=30.0) as client:
            # Use Google Custom Search API
            response = client.get(
                "https://www.googleapis.com/customsearch/v1",
                params={
                    "key": GOOGLE_API_KEY,
                    "cx": GOOGLE_SEARCH_ENGINE_ID,
                    "q": search_query,
                    "num": 10  # Get top 10 results
                }
            )
            
            print(f"üîç Google response status: {response.status_code}")
            
            if response.status_code != 200:
                print(f"‚ö†Ô∏è Google Search error: {response.text}")
                return None
            
            data = response.json()
            items = data.get("items", [])
            
            if not items:
                print(f"üì≠ No results found")
                return {
                    "found": False,
                    "num_results": 0
                }
            
            print(f"‚úÖ Found {len(items)} results mentioning this image")
            
            # Analyze the results
            domains = []
            suspicious_keywords = ["ai", "midjourney", "dalle", "stable-diffusion", "generated", "synthetic", "fake", "artificial"]
            suspicious_count = 0
            
            for item in items:
                link = item.get("link", "")
                title = item.get("title", "").lower()
                snippet = item.get("snippet", "").lower()
                
                # Extract domain
                item_domain = urlparse(link).netloc
                domains.append(item_domain)
                
                # Check for AI-related keywords
                text = title + " " + snippet
                if any(keyword in text for keyword in suspicious_keywords):
                    suspicious_count += 1
            
            # Calculate suspicion score
            suspicion_ratio = suspicious_count / len(items) if items else 0
            
            print(f"üìä Suspicious results: {suspicious_count}/{len(items)} ({int(suspicion_ratio*100)}%)")
            
            return {
                "found": True,
                "num_results": len(items),
                "domains": list(set(domains))[:5],  # Top 5 unique domains
                "suspicious_ratio": suspicion_ratio,
                "suspicious_count": suspicious_count
            }
            
    except Exception as e:
        print(f"‚ö†Ô∏è Google Search error: {str(e)}")
        return None


def detect_with_huggingface(image_data):
    """Detect AI using Hugging Face SDXL detector"""
    
    if not HUGGINGFACE_API_KEY:
        print("‚ö†Ô∏è No Hugging Face API key, skipping")
        return None
    
    try:
        import base64
        
        print(f"ü§ó Calling Hugging Face SDXL detector...")
        
        # Convert image to base64
        image_b64 = base64.b64encode(image_data).decode('utf-8')
        
        with httpx.Client(timeout=30.0) as client:
            response = client.post(
                "https://api-inference.huggingface.co/models/Organika/sdxl-detector",
                headers={
                    "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "inputs": image_b64
                }
            )
            
            print(f"ü§ó HF Response status: {response.status_code}")
            
            if response.status_code == 503:
                print("‚è≥ Model loading, retrying in 10 seconds...")
                import time
                time.sleep(10)
                response = client.post(
                    "https://api-inference.huggingface.co/models/Organika/sdxl-detector",
                    headers={
                        "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={"inputs": image_b64}
                )
            
            if response.status_code != 200:
                print(f"‚ö†Ô∏è HF API error: {response.status_code}")
                return None
            
            data = response.json()
            print(f"ü§ó HF Response: {data}")
            
            # Parse response - format: [{"label": "artificial", "score": 0.99}]
            artificial_score = 0.5
            if isinstance(data, list) and len(data) > 0:
                for item in data:
                    if item.get("label") == "artificial":
                        artificial_score = item.get("score", 0.5)
                        break
            
            print(f"‚úÖ HF AI confidence: {artificial_score}")
            
            return {
                "provider": "Hugging Face",
                "ai_confidence": artificial_score,
                "verdict": "AI-generated" if artificial_score > 0.5 else "Real"
            }
            
    except Exception as e:
        print(f"‚ö†Ô∏è HF detection error: {str(e)}")
        return None


def detect_image_video_from_data(file_data, filename, is_video=False):
    """Detect AI in image/video from raw file data"""
    
    if not AIORNOT_API_KEY:
        return create_mock_result(50, "No AIorNOT API key configured")
    
    try:
        import base64
        
        print(f"üîç Detecting {'video' if is_video else 'image'} from uploaded file: {filename}")
        
        # Encode file to base64
        file_b64 = base64.b64encode(file_data).decode('utf-8')
        
        # Prepare multipart form data
        with httpx.Client(timeout=60.0) as client:
            # AIorNOT expects file upload
            files = {
                'object': (filename, file_data, 'application/octet-stream')
            }
            
            print(f"üì§ Uploading to AIorNOT...")
            response = client.post(
                "https://api.aiornot.com/v1/reports/image",
                headers={
                    "Authorization": f"Bearer {AIORNOT_API_KEY}"
                },
                files=files
            )
            
            print(f"üì• AIorNOT response: {response.status_code}")
            
            if response.status_code != 200:
                print(f"‚ö†Ô∏è AIorNOT error: {response.text}")
                return create_mock_result(50, f"AIorNOT API Error: {response.status_code}")
            
            data = response.json()
            print(f"‚úÖ AIorNOT response data: {data}")
            
            # Get Hugging Face result too
            hf_result = detect_with_huggingface(file_data)
            
            # Collect all results
            all_results = []
            
            # AIorNOT result
            ai_generated = data.get("report", {}).get("ai_generated", {})
            aiornot_confidence = ai_generated.get("confidence", 0.5)
            all_results.append({
                "provider": "AIorNOT",
                "ai_confidence": aiornot_confidence,
                "verdict": ai_generated.get("verdict", "unknown")
            })
            
            # Hugging Face result
            if hf_result:
                all_results.append(hf_result)
            
            # Calculate ensemble confidence
            combined_ai_confidence = sum(r["ai_confidence"] for r in all_results) / len(all_results)
            
            # Apply amplification to make scores more decisive
            combined_ai_confidence = amplify_confidence(combined_ai_confidence)
            
            # Calculate trust score (inverse of AI confidence)
            trust_score = int((1 - combined_ai_confidence) * 100)
            label_info = get_label_with_explanation(trust_score)
            
            print(f"üìä Final trust score: {trust_score} ({label_info['label']})")
            
            # Build evidence
            evidence = []
            
            for result in all_results:
                provider = result["provider"]
                ai_conf = result["ai_confidence"]
                verdict = result.get("verdict", "unknown")
                
                signal = f"{provider}: {verdict} ({int(ai_conf * 100)}% AI confidence)"
                
                evidence.append({
                    "category": f"AI Detection - {provider}",
                    "signal": signal,
                    "confidence": float(ai_conf),
                    "details": result
                })
            
            # Add combined result
            evidence.insert(0, {
                "category": "Combined Analysis",
                "signal": f"Ensemble score from {len(all_results)} detectors: {int(combined_ai_confidence * 100)}% AI confidence",
                "confidence": float(combined_ai_confidence),
                "details": {
                    "num_detectors": len(all_results),
                    "combined_confidence": combined_ai_confidence
                }
            })
            
            return {
                "trust_score": {
                    "score": trust_score,
                    "label": label_info["label"],
                    "explanation": label_info["explanation"],
                    "confidence": label_info["confidence"],
                    "recommended_action": label_info["action"],
                    "confidence_band": [max(0, trust_score - 10), min(100, trust_score + 10)]
                },
                "evidence": evidence,
                "metadata": {
                    "filename": filename,
                    "provider": "Ensemble Detection",
                    "content_type": "video" if is_video else "image",
                    "report_id": data.get("id")
                }
            }
            
    except Exception as e:
        error_msg = f"Detection error: {str(e)}"
        print(f"‚ö†Ô∏è {error_msg}")
        print(f"Full traceback: {traceback.format_exc()}")
        return create_mock_result(50, error_msg)


def detect_image_video(url):
    """Detect AI in image/video from URL using AIorNOT with ensemble scoring"""
    
    if not AIORNOT_API_KEY:
        return create_mock_result(50, "No AIorNOT API key configured")
    
    try:
        print(f"üîç Calling AIorNOT for URL: {url}")
        
        with httpx.Client(timeout=60.0) as client:
            response = client.post(
                "https://api.aiornot.com/v1/reports/image",
                headers={
                    "Authorization": f"Bearer {AIORNOT_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={"object": url}
            )
            
            print(f"üì• AIorNOT response status: {response.status_code}")
            
            if response.status_code != 200:
                print(f"‚ö†Ô∏è AIorNOT error: {response.text}")
                return create_mock_result(50, f"API Error: {response.status_code}")
            
            data = response.json()
            print(f"‚úÖ Got AIorNOT response")
            
            # Download image for Hugging Face
            image_response = client.get(url, timeout=30.0)
            if image_response.status_code == 200:
                image_data = image_response.content
                hf_result = detect_with_huggingface(image_data)
            else:
                print(f"‚ö†Ô∏è Could not download image for HF: {image_response.status_code}")
                hf_result = None
            
            # Google reverse image search
            google_result = reverse_image_search(url)
            
            # Collect all AI detection results
            all_results = []
            
            # AIorNOT result
            ai_generated = data.get("report", {}).get("ai_generated", {})
            aiornot_confidence = ai_generated.get("confidence", 0.5)
            all_results.append({
                "provider": "AIorNOT",
                "ai_confidence": aiornot_confidence,
                "verdict": ai_generated.get("verdict", "unknown")
            })
            
            # Hugging Face result
            if hf_result:
                all_results.append(hf_result)
            
            # Calculate ensemble confidence (average of all detectors)
            combined_ai_confidence = sum(r["ai_confidence"] for r in all_results) / len(all_results)
            
            # Apply amplification to make scores more decisive
            combined_ai_confidence = amplify_confidence(combined_ai_confidence)
            
            # Factor in Google provenance if suspicious
            provenance_evidence = None
            if google_result and google_result.get("found"):
                suspicious_ratio = google_result.get("suspicious_ratio", 0)
                if suspicious_ratio > 0.3:  # More than 30% suspicious
                    # Increase AI confidence slightly based on suspicious findings
                    provenance_boost = suspicious_ratio * 0.15  # Max 15% boost
                    combined_ai_confidence = min(1.0, combined_ai_confidence + provenance_boost)
                    
                    provenance_evidence = {
                        "category": "Provenance Analysis",
                        "signal": f"Found {google_result['num_results']} mentions online, {google_result['suspicious_count']} contain AI-related keywords",
                        "confidence": suspicious_ratio,
                        "details": google_result
                    }
            
            # Calculate trust score (inverse of AI confidence, scaled 0-100)
            trust_score = int((1 - combined_ai_confidence) * 100)
            label_info = get_label_with_explanation(trust_score)
            
            print(f"üìä Final trust score: {trust_score} ({label_info['label']})")
            
            # Get generator info if available
            generator_info = ai_generated.get("generator", {})
            top_generators = []
            if generator_info:
                # Get top 3 generators by confidence
                # Handle both dict and float values
                try:
                    sorted_items = []
                    for gen_name, gen_value in generator_info.items():
                        # Extract confidence - might be a dict or a float
                        if isinstance(gen_value, dict):
                            confidence = gen_value.get("confidence", 0)
                        else:
                            confidence = float(gen_value) if gen_value else 0
                        sorted_items.append((gen_name, confidence))
                    
                    # Sort by confidence and take top 3
                    sorted_items.sort(key=lambda x: x[1], reverse=True)
                    top_generators = [f"{gen}: {int(conf*100)}%" for gen, conf in sorted_items[:3] if conf > 0.5]
                except Exception as gen_error:
                    print(f"‚ö†Ô∏è Error parsing generators: {gen_error}")
                    top_generators = []
            
            # Build evidence from all results
            evidence = []
            
            for result in all_results:
                provider = result["provider"]
                ai_conf = result["ai_confidence"]
                verdict = result.get("verdict", "unknown")
                
                signal = f"{provider}: {verdict} ({int(ai_conf * 100)}% AI confidence)"
                
                # Add generator info for AIorNOT
                if provider == "AIorNOT" and top_generators:
                    signal += f" - Detected: {', '.join(top_generators)}"
                
                evidence.append({
                    "category": f"AI Detection - {provider}",
                    "signal": signal,
                    "confidence": float(ai_conf),
                    "details": result
                })
            
            # Add combined result
            evidence.insert(0, {
                "category": "Combined Analysis",
                "signal": f"Ensemble score from {len(all_results)} detectors: {int(combined_ai_confidence * 100)}% AI confidence",
                "confidence": float(combined_ai_confidence),
                "details": {
                    "num_detectors": len(all_results),
                    "combined_confidence": combined_ai_confidence
                }
            })
            
            # Add provenance evidence if available
            if provenance_evidence:
                evidence.append(provenance_evidence)
            
            return {
                "trust_score": {
                    "score": trust_score,
                    "label": label_info["label"],
                    "explanation": label_info["explanation"],
                    "confidence": label_info["confidence"],
                    "recommended_action": label_info["action"],
                    "confidence_band": [max(0, trust_score - 10), min(100, trust_score + 10)]
                },
                "evidence": evidence,
                "metadata": {
                    "url": url,
                    "provider": "AI or Not v2",
                    "content_type": "image",
                    "report_id": data.get("id")
                }
            }
            
    except Exception as e:
        error_msg = f"AI or Not detection error: {str(e)}"
        print(f"‚ö†Ô∏è {error_msg}")
        print(f"Full traceback: {traceback.format_exc()}")
        return create_mock_result(50, error_msg)


# ============================================================
# TEXT DETECTION - USING WINSTON AI
# ============================================================

def detect_text_winston(text_content):
    """
    Detect AI-generated text using Winston AI
    Uses JSON-RPC 2.0 format via MCP server
    High accuracy detection with 2,500 free credits
    """
    
    if not WINSTON_API_KEY:
        print("‚ö†Ô∏è No Winston AI API key")
        return None
    
    try:
        print(f"üîç Calling Winston AI for text detection...")
        print(f"üìù Text length: {len(text_content)} characters")
        
        # Winston AI requires minimum 300 characters for text detection
        if len(text_content) < 300:
            print(f"‚ö†Ô∏è Text too short ({len(text_content)} chars), Winston AI requires 300+ chars")
            print(f"   Falling back to backup detector")
            return None
        
        # Winston AI MCP endpoint using JSON-RPC 2.0
        with httpx.Client(timeout=30.0) as client:
            response = client.post(
                "https://api.gowinston.ai/mcp/v1",
                headers={
                    "Content-Type": "application/json",
                    "Accept": "application/json"
                },
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "ai-text-detection",
                        "arguments": {
                            "text": text_content,
                            "apiKey": WINSTON_API_KEY
                        }
                    }
                }
            )
            
            print(f"üîç Winston AI response status: {response.status_code}")
            
            if response.status_code != 200:
                print(f"‚ö†Ô∏è Winston AI error: {response.status_code} - {response.text}")
                return None
            
            data = response.json()
            print(f"‚úÖ Winston AI response: {data}")
            
            # Parse Winston AI JSON-RPC response
            # Expected format: {"jsonrpc": "2.0", "id": 1, "result": {"content": [{"text": "..."}]}}
            result = data.get("result", {})
            
            # Extract the actual detection result from content
            content = result.get("content", [])
            if content and len(content) > 0:
                # Parse the text response which contains the detection results
                text_result = content[0].get("text", "")
                print(f"üìä Winston result text: {text_result}")
                
                # Winston returns text with score - try to extract it
                # Format might be: "Score: 0.95" or similar
                # For now, parse the text response
                
                # Try to find AI probability in the response
                ai_confidence = 0.5  # Default
                
                # Parse score from text (Winston returns detailed analysis)
                # We'll look for patterns like "AI: 95%" or "Human: 5%"
                import re
                
                # Try to extract percentage or score
                score_match = re.search(r'(\d+)%?\s*(AI|artificial|generated)', text_result, re.IGNORECASE)
                if score_match:
                    ai_confidence = float(score_match.group(1)) / 100
                else:
                    # Try to find "human" percentage and invert
                    human_match = re.search(r'(\d+)%?\s*(human|real)', text_result, re.IGNORECASE)
                    if human_match:
                        ai_confidence = 1 - (float(human_match.group(1)) / 100)
                
                print(f"‚úÖ Winston AI confidence: {ai_confidence:.2%}")
                
                # Determine verdict
                is_human = ai_confidence < 0.5
                
                return {
                    "provider": "Winston AI",
                    "ai_confidence": ai_confidence,
                    "verdict": "Human-written" if is_human else "AI-generated",
                    "raw_response": data,
                    "analysis_text": text_result
                }
            else:
                print(f"‚ö†Ô∏è Unexpected Winston response format")
                return None
            
    except Exception as e:
        print(f"‚ö†Ô∏è Winston AI error: {str(e)}")
        print(f"Traceback: {traceback.format_exc()}")
        return None


def detect_text_huggingface(text_content):
    """
    Detect AI-generated text using OpenAI's RoBERTa Large detector
    BACKUP method if Winston AI fails
    """
    
    if not HUGGINGFACE_API_KEY:
        print("‚ö†Ô∏è No Hugging Face API key")
        return None
    
    try:
        print(f"ü§ó Calling OpenAI RoBERTa Large (backup)...")
        
        # Truncate if too long
        MAX_CHARS = 2000
        text_to_check = text_content[:MAX_CHARS] if len(text_content) > MAX_CHARS else text_content
        
        with httpx.Client(timeout=30.0) as client:
            response = client.post(
                "https://api-inference.huggingface.co/models/openai-community/roberta-large-openai-detector",
                headers={
                    "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={"inputs": text_to_check}
            )
            
            if response.status_code == 503:
                print("‚è≥ Model loading, waiting 10 seconds...")
                import time
                time.sleep(10)
                response = client.post(
                    "https://api-inference.huggingface.co/models/openai-community/roberta-large-openai-detector",
                    headers={"Authorization": f"Bearer {HUGGINGFACE_API_KEY}"},
                    json={"inputs": text_to_check}
                )
            
            if response.status_code != 200:
                print(f"‚ö†Ô∏è Backup API error: {response.status_code}")
                return None
            
            data = response.json()
            
            # Parse response
            ai_confidence = 0.5
            if isinstance(data, list) and len(data) > 0:
                results = data[0] if isinstance(data[0], list) else data
                for result in results:
                    label = result.get("label", "")
                    score = result.get("score", 0.5)
                    if label == "LABEL_1":
                        ai_confidence = score
                        break
            
            print(f"‚úÖ Backup AI confidence: {ai_confidence:.2%}")
            
            return {
                "provider": "OpenAI RoBERTa (Backup)",
                "ai_confidence": ai_confidence,
                "verdict": "AI-generated" if ai_confidence > 0.5 else "Human-written",
                "raw_response": data
            }
            
    except Exception as e:
        print(f"‚ö†Ô∏è Backup detector error: {str(e)}")
        return None


def detect_text(text_content):
    """
    Detect AI in text using Winston AI (primary) with Hugging Face backup
    """
    
    print(f"üîç Starting text AI detection (length: {len(text_content)} chars)")
    
    # Try Winston AI first
    result = detect_text_winston(text_content)
    
    # If Winston fails, use Hugging Face backup
    if result is None:
        print(f"‚ö†Ô∏è Winston AI unavailable, using backup detector")
        result = detect_text_huggingface(text_content)
    
    # If both failed, return error
    if result is None:
        print(f"‚ùå Text detection failed: All detectors unavailable")
        return create_mock_result(50, "Text detection API unavailable")
    
    # Calculate trust score (inverse of AI confidence)
    ai_confidence = result.get("ai_confidence", 0.5)
    trust_score = int((1 - ai_confidence) * 100)
    label_info = get_label_with_explanation(trust_score)
    
    print(f"üìä AI confidence: {int(ai_confidence * 100)}%")
    print(f"üìä Final trust score: {trust_score} ({label_info['label']})")
    
    return {
        "trust_score": {
            "score": trust_score,
            "label": label_info["label"],
            "explanation": label_info["explanation"],
            "confidence": label_info["confidence"],
            "recommended_action": label_info["action"],
            "confidence_band": [max(0, trust_score - 10), min(100, trust_score + 10)]
        },
        "evidence": [
            {
                "category": "AI Text Detection",
                "signal": f"{result['provider']}: {result['verdict']} ({int(ai_confidence * 100)}% AI confidence)",
                "confidence": float(ai_confidence),
                "details": result
            }
        ],
        "metadata": {
            "provider": result["provider"],
            "content_type": "text",
            "text_length": len(text_content),
            "detector": result["provider"]
        }
    }


# ============================================================
# HELPER FUNCTIONS
# ============================================================

def amplify_confidence(confidence):
    """
    Amplify confidence scores to make them more decisive
    Pushes values away from 0.5 (inconclusive) toward extremes
    
    Examples:
    0.54 -> 0.62 (more decisive toward "not AI")
    0.63 -> 0.76 (even more decisive)
    0.90 -> 0.97 (very confident stays very confident)
    """
    # Center around 0.5
    centered = confidence - 0.5
    # Apply power function to amplify (1.5 is good balance)
    amplified = centered * (abs(centered) ** 0.3) * 2.5
    # Shift back and clamp to [0, 1]
    result = 0.5 + amplified
    return max(0.0, min(1.0, result))


def get_label_with_explanation(score):
    """Convert score to consumer-friendly label with explanation"""
    if score >= 65:
        return {
            "label": "Likely Real",
            "explanation": "This content appears to be authentic. Our AI detection found strong indicators that this was created by a human or captured with a real camera.",
            "confidence": "High",
            "action": "This content is likely trustworthy."
        }
    elif score >= 50:
        return {
            "label": "Probably Real", 
            "explanation": "This content likely appears authentic, but we detected some minor inconsistencies. This could be due to image editing or compression.",
            "confidence": "Moderate-High",
            "action": "This content is probably trustworthy, but verify important details."
        }
    elif score >= 35:
        return {
            "label": "Probably Fake",
            "explanation": "This content shows signs of AI generation. We detected patterns commonly found in AI-created images or text.",
            "confidence": "Moderate-High",
            "action": "Be cautious. This content may be AI-generated or heavily manipulated."
        }
    else:
        return {
            "label": "Likely Fake",
            "explanation": "This content appears to be AI-generated. We found strong indicators of synthetic creation, including telltale artifacts and patterns typical of AI generators.",
            "confidence": "High",
            "action": "This content is likely fake. Do not trust without additional verification."
        }

def get_label(score):
    """Convert score to consumer-friendly label (backward compatibility)"""
    return get_label_with_explanation(score)["label"]

def create_mock_result(score, reason):
    """Create mock result when API unavailable"""
    print(f"üîß Creating mock result: score={score}, reason={reason}")
    return {
        "trust_score": {
            "score": score,
            "label": get_label(score),
            "confidence_band": [max(0, score - 10), min(100, score + 10)]
        },
        "evidence": [
            {
                "category": "System",
                "signal": reason,
                "confidence": 0.5
            }
        ],
        "metadata": {
            "note": "Mock result - check API keys",
            "reason": reason
        }
    }
